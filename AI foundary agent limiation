1. What is Azure AI Foundry Agent Service
Azure AI Foundry Agent Service is a platform within Azure AI Foundry that lets you build, deploy, and manage intelligent agents for enterprise use.
Each agent combines a large language model (LLM), custom instructions, and connected tools or data sources to process inputs and generate outputs.
The service manages runtime, orchestration, identity, governance, and integration — including connections to enterprise data through sources like SharePoint, Azure AI Search, or Microsoft Fabric Data Agent for seamless data access and automation. 

2. Typical Flow: Connect External Application → Foundry Agent
Here’s a step-by-step high-level flow you can document for plugging an external application into Foundry Agent via SDK/API:
External Application Integration
1.	From the external application side (for example, a web app or backend service), install or reference the SDK or REST API for Foundry Agent. Microsoft Learn+1
2.	Set environment variables or configuration parameters: e.g., project endpoint, model deployment name. 
3.	Authenticate the external app with Azure credentials (e.g., DefaultAzureCredential, service-principal credentials).
4.	From your app, call the agent endpoint: usually you create a “thread” or “run” for the agent with input content, await the result, retrieve the messages or results.
5.	Handle tool invocation: when the agent invokes a tool, results come back to the thread and then your application receives the output as part of the run result.
6.	Post-processing: your application can take the agent’s output and render it (for example to UI), or trigger further flows (e.g., call your own service based on the response).
7.	Monitoring & observability: your external app should log request/responses, monitor latency, handle retry/failure scenarios, and feed telemetry into your monitoring stack (e.g., Application Insights) for the agent service.

3. Limitations & “What won’t work” / Things to watch
When integrating your external application with Foundry Agent, there are several built-in service limitations and practical constraints. You should include these in your document so stakeholders understand what won’t work or is constrained.
Key Quotas & Limits
Limit	Value	Implication for external app
Maximum number of files per agent/thread	10,000 	If your external app expects to upload >10k files for the agent context in a thread, it will be blocked.
Maximum file size for agents & fine‐tuning	512 MB 	Large documents/binaries >512 MB cannot be uploaded. External app must chunk or split.
Maximum size for all uploaded files for agents	~300 GB 	If your knowledge base is huge and you load >300 GB, you hit the limit.
Maximum file size in tokens for attaching to a vector store	2,000,000 tokens 	External app must ensure data ingested for vector store doesn’t exceed token-limit in one go.
Maximum number of messages per thread	100,000 	If your app initiates very long conversation threads, you’ll hit the message-limit.
Maximum size of text content per message	~1,500,000 characters 	If your external app sends huge prompt/inputs >1.5 million characters, invalid.
Maximum number of tools registered per agent	128 	If you plan to register many (hundreds) of tools/actions for the agent, the cap is 128.
Functional / Integration Limitations
•	Connected agents cannot call local functions using the Function-Calling tool: For example, when you use “connected agents” (agent-to-agent) via the connected-agent mechanism, you cannot use the built-in function-calling tool for local functions; rather you should use OpenAPI or Azure Functions 
•	Citations are not guaranteed for connected agents: If you rely on the agent producing citations (e.g., to show sources in your UI), the service notes that citations may not always be returned. Microsoft Learn
•	Latency and throughput issues: External app expecting real-time fast responses might face latency if the agent has heavy context/tool calls; users report latency issues in forum
•	External App Identity/Permissions issues: When your external app triggers the agent (especially via Azure Logic Apps or managed identity), the agent’s tool invocation (e.g., SharePoint connector) might fail due to permissions. Example: when the call is via Logic App, tool invocation failed with “sharepoint_tool_server_error” because the Managed Identity 
•	Streaming output and progressive UI: While streaming is possible in some SDKs, there is ambiguity whether Foundry Agent supports streaming fully in every scenario. External app UI expecting live token-by-token streaming may need confirmation.
•	Multimodal/Visual support: While Foundry supports multimodal (images, video, etc) through models like GPT-4o, your external app must handle the upload/processing limits and may find unsupported formats or large visual data getting blocked. (Though direct doc cites for visual limits are sparse)
•	Quota-exceeding failures: Your external app must design for error-handling when quotas are exceeded (e.g., too many files, too large input) because the service will reject the invocation rather than auto-scale beyond limits.
Things that “won’t work” 
•	You cannot assume unlimited conversation length: threads can’t grow past 100k messages or huge character sizes.
•	You cannot assume every tool invocation succeeds: external app must be ready for tool-call failures (permissions, region, tool-availability).
•	You cannot expect perfect citations in connected-agent scenarios.
•	You cannot guarantee every model supports every tool or action; model/tool compatibility must be verified.
•	If you upload extremely large visual/video files (>512 MB) the agent may not ingest them. External app must preprocess or chunk.
•	If your external app depends on ultra-low latency (<100 ms) for each agent invocation, you may fail to meet expectations due to tool/processing overhead or region constraints.

